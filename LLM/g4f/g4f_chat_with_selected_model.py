# conda activate extras2

# pip install -U g4f
# pip install -U nodriver platformdirs

import g4f
import time
import asyncio
from datetime import datetime
from g4f.models import ModelUtils

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
def get_text_models():
    excluded_keywords = [
        'vision', 'image', 'img', 'dall-e', 'clip', 'whisper', 'flux',
        'tts', 'speech', 'audio', 'ocr', 'stable-diffusion', 'sd'
    ]

    return [
        model for model in ModelUtils.convert
        if not any(keyword in model.lower() for keyword in excluded_keywords)
    ]

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏
async def get_model_response(model, messages):
    try:
        start_time = time.time()
        response = await g4f.ChatCompletion.create_async(
            model=model,
            messages=messages,
        )
        response_time = time.time() - start_time
        return response, response_time
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {str(e)}", 0

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —á–∞—Ç–∞
async def chat_with_model(model_name):
    print(f"\nüöÄ –ù–∞—á–∞—Ç —á–∞—Ç —Å –º–æ–¥–µ–ª—å—é: {model_name}")
    print("üí¨ –í–≤–µ–¥–∏—Ç–µ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
    print("=" * 50)

    messages = []
    start_time = datetime.now()
    print(f"‚è± –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏: {start_time.strftime('%H:%M:%S')}")

    while True:
        user_input = input("\n–í—ã: ")

        if user_input.lower() == 'exit':
            print("\n–°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
            session_duration = datetime.now() - start_time
            print(f"‚è± –û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏: {session_duration}")
            return

        messages.append({"role": "user", "content": user_input})

        print(f"\n‚åõ {model_name} –¥—É–º–∞–µ—Ç...")
        response, response_time = await get_model_response(model_name, messages)

        messages.append({"role": "assistant", "content": response})

        print(f"\n{model_name}: {response}")
        print(f"‚è± –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f} —Å–µ–∫—É–Ω–¥")
        print("-" * 50)

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def main():
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    text_models = get_text_models()

    if not text_models:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.")
        return

    # –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π —Å –Ω–æ–º–µ—Ä–∞–º–∏
    print("\nüìö –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏:")
    for i, model in enumerate(text_models, 1):
        print(f"{i}. {model}")

    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    while True:
        try:
            choice = int(input("\nüëâ –í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è —á–∞—Ç–∞: "))
            if 1 <= choice <= len(text_models):
                selected_model = text_models[choice - 1]
                break
            else:
                print(f"‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ {len(text_models)}")
        except ValueError:
            print("‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä")

    # –ó–∞–ø—É—Å–∫–∞–µ–º —á–∞—Ç —Å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
    await chat_with_model(selected_model)

if __name__ == "__main__":
    asyncio.run(main())